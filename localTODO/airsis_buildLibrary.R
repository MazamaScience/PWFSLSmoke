#' @keywords AIRSIS
#' @export
#' @title Build a Local RData Library from AIRSIS
#' @param provider identifier used to modify baseURL \code{['APCD'|'USFS']}
#' @param unitIDs vector of character or numeric unit identifiers
#' @param years vector of years for which to download data
#' @param logLevel log level for output \code{['TRACE','DEBUG','INFO','WARNING','ERROR','FATAL']}
#' @param transcript filename for logging output
#' @param outputDir directory where data files and transcript will be written
#' @param baseUrl base URL for data queries
#' @description Smoke monitoring data from airsis.com is downloaded, quality controlled
#' and converted in to a collection of .RData files, each containing a \code{ws_monitor}
#' for a particular UnitID.
#' 
#' By default, a transcript file will be generated containing information on the progress
#' of data downlaod, quality control and restructuring. More detailed information is
#' generated by setting \code{logLevel='DEBUG'}.
#' 
#' Setting \code{transcript=NULL} causes output to be sent to the console.
#' @details When no unitIDs are supplied (the default), a range of unitIDs is generated that
#' covers all AIRSIS monitor known to exist for each provider as of May, 2016. The range will
#' contain some unitIDs for which no monitors exist so it is normal to see log messages
#' for unitIDs with no data.
#' @return Vector of file names created.
#' @seealso \link{monitor_combineLibraryFiles}
#' @references \href{http://usfs.airsis.com}{Interagency Real Time Smoke Monitoring}
#' @examples
#' \dontrun{
#' files <- airsis_buildLibrary('APCD', years=2010:2015, outputDir='~/Data/AIRSIS')
#' monitor_combineLibraryFiles('~/Data/AIRSIS', files, 'AIRSIS_APCD.RData')
#' apcd_CA <- <- airsis_load(stateCodes='CA', url='~/Data/AIRSIS/AIRSIS_APCD.RData')
#' monitor_leaflet(apcd_CA)
#' }

airsis_buildLibrary <- function(provider='USFS', unitIDs=NULL, years=2000:2015,
                                logLevel=futile.logger::INFO, transcript='AIRSIS_TRANSCRIPT.txt',
                                outputDir=getwd(),
                                baseUrl="http://xxxx.airsis.com/vision/common/CSVExport.aspx?") {
  
  # Set up a new transcript file
  if (is.null(transcript)) {
    futile.logger::flog.appender(futile.logger::appender.console())
  } else {
    transcriptPath <- file.path(outputDir,transcript)
    file.remove(transcriptPath)
    futile.logger::flog.appender(futile.logger::appender.file(transcriptPath))
  }
  
  # Set log level
  futile.logger::flog.threshold(logLevel)
  
  # Silence other warning messages
  options(warn=-1) # -1=ignore, 0=save/print, 1=print, 2=error
  
  # List where saved filenames are stored
  filenames <- list()
  
  if ( is.null(unitIDs) ) {
   
    if (toupper(provider) == 'APCD') {
      
      # Process AIRSIS files located at USFS.airsis.com -----------------------------
      
      dataram <- 1:2
      BAM1020 <- c(7, 1012)
      ebamNew <- 4:6
      IridiumEbams <- 1002:1028 # with other flavors mixed in
      IridiumEsams <- 1000:1001
      
      unitIDs <- c(1:9,1000:1030)
      
    } else if (toupper(provider) == 'ARB2') {
      
      unitIDs <- 1000:1040
      
    } else if (toupper(provider) == 'MARIPOSA') {
      
      unitIDs <- 1000
      
    } else if (toupper(provider) == 'USFS') {
      
      # Process AIRSIS files located at USFS -----------------------------
      
      # Datarams <- c(1:43) # with a few missing and a few extra larger numbers
      # 
      # BAM1020s <- c(49,50,84,1015) # These appear when clicking on "Bam 1020" at the URL above
      # 
      # eBams <- c(21,36,48,53,57,58,59,60,70,72,74)
      # 
      # eBamNews <- c(45:96) # with a few missing
      
      earlyEbams <- c(1:99) # with other flavors mixed in
      
      IridiumEbams <- c(1000:1055,2000) # with other flavors mixed in
      IridiumEbams <- c(1000:1005) # DELETEME
      
      unitIDs <- c(1:99,1000:1055,2000)
    }
     
  }
  
  # Begin data access ---------------------------------------------------------
  
  for (unitID in unitIDs) {
    
    futile.logger::flog.info('Working on unitID %s ---------------------------------------------------------', unitID)
    
    dfList <- list()
    
    for (year in years) {
      
      # Download data
      
      futile.logger::flog.debug('Downloading %s data for unitID %s', year, unitID)
      
      startdate <- paste0(year,'0101')
      enddate <- paste0(year, '1231')
      
      result <- try( fileString <- airsis_downloadData(provider, unitID, startdate, enddate),
                     silent=TRUE )

      if ( class(result)[1] == "try-error" ) {
        err_msg <- geterrmessage()
        futile.logger::flog.warn('Skipping unitID %s: %s', unitID, err_msg)
        break
      }
      
      # When no data is available, only a single line is found
      lines <- readr::read_lines(fileString)
      if (length(lines) == 1) {
        futile.logger::flog.debug('Skipping %s for unitID %s: no data found', year, unitID)
        break
      }
      
      # Parse data into a dataframe
      
      futile.logger::flog.debug('Parsing %s lines of %s data for unitID %s', length(lines), year, unitID)

      result <- try( df <- airsis_parseData(fileString),
                     silent=TRUE )
      
      if ( class(result)[1] == "try-error" ) {
        
        err_msg <- geterrmessage()
        if (stringr::str_detect(err_msg,'parsing is not supported')) {
          futile.logger::flog.warn('Skipping unitID %s: %s', unitID, err_msg)
          break
        } else if (stringr::str_detect(err_msg,'No data returned')) {
          futile.logger::flog.debug('Skipping %s for unitID %s: no data found', year, unitID)
          next
        } else {
          futile.logger::flog.warn('Skipping %s for unitID %s: %s', year, unitID, err_msg)
          next
        }
        
      } else {
        
        futile.logger::flog.debug('%s had %s rows of data', year, nrow(df))
        dfList[[as.character(year)]] <- df 
        
      }
      
    } # End of years loop
    
    # Create a combined dataframe with all years
    # NOTE:  dplyr returns objects of class "tbl_df" which can be confusing. We undo that with as.data.frame().
    df <- as.data.frame( dplyr::bind_rows(dfList) )
    
    # Sanity check -- do we have any data?
    yearsString <- paste0(years[1],'-',years[length(years)])
    futile.logger::flog.info('unitID %s has %s rows of raw data for years %s', unitID, nrow(df), yearsString)
    if ( nrow(df) == 0 ) next
    
    # Now create a ws_monitor object from this
    result <- try( ws_monitor <- airsis_createMonitorObject(df, clusterDiameter=1000),
                   silent=TRUE )
    
    if ( class(result)[1] == "try-error" ) {
      err_msg <- geterrmessage()
      futile.logger::flog.warn('Skipping unitID %s: %s', unitID, err_msg)
      next
    } else {
      instrumentID <- stringr::str_sub(ws_monitor$meta$monitorID[1],1,-6) # strip off trailing "__###" (deployment id)
      filename <- paste0(instrumentID,'.RData')
      filenames[[unitID]] <- filename
      filepath <- file.path(outputDir, filename)
      save(ws_monitor, file=filepath)
      futile.logger::flog.info('Saving data as %s', filepath)
    }
    
  } # End of unitIDs loop
  
  # Return vector of filenames generated
  return(unlist(filenames))
  
}

